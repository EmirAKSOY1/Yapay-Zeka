# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CfF94fKmT4UIPcaj8D28Ai2VIeXDsKxY
"""

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
nltk.download('stopwords')
nltk.download('punkt')
import re
def harfdegistir(cumle):
    listcumle0 = list(cumle)
    for i in range(0,len(listcumle0)):
        if listcumle0[i] == "ü":
            listcumle0[i] = "u"
        elif listcumle0[i] == "Ü":
            listcumle0[i] = "U"
        elif listcumle0[i] == "ö":
            listcumle0[i] = "o"
        elif listcumle0[i] == "Ö":
            listcumle0[i] = "O"
        elif listcumle0[i] == "İ":
            listcumle0[i] = "I"
        elif listcumle0[i] == "ç":
            listcumle0[i] = "c"
        elif listcumle0[i] == "Ç":
            listcumle0[i] = "C"
        elif listcumle0[i] == "ğ":
            listcumle0[i] = "g"
        elif listcumle0[i] == "Ğ":
            listcumle0[i] = "G"
        elif listcumle0[i] == "ş":
            listcumle0[i] = "s"
        elif listcumle0[i] == "Ş":
            listcumle0[i] = "S"
        elif listcumle0[i] == "ı":
            listcumle0[i] = "i"

    cumle0 = ''.join(listcumle0)

    cumle1 = re.sub("[^a-zA-Z]", " ", cumle0)
    cumle2 = cumle1.lower()

    cumle2 = nltk.word_tokenize(cumle2)
    cumle2 = [word for word in cumle2 if not word in set(stopwords.words("turkish"))]

    cumle3 = " ".join(cumle2)

    return cumle3
df = pd.read_csv('haberler.csv')

df.head(20)

df= df.dropna()
SonGorus = []
X = df["text"].values
for i in range(len(X)):
    X_ = harfdegistir(X[i])
    SonGorus.append(X_)
df['text'] = SonGorus
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, random_state=42)
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)
max_words = 1000
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)
max_len = 100  # Cümlenin maksimum uzunluğu
X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')
from tensorflow.keras.layers import Bidirectional, Dropout

# Modeli oluştur
model = Sequential()
model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))
model.add(Bidirectional(LSTM(128, return_sequences=True)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.2))
model.add(Dense(7, activation='softmax'))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

verim = model.fit(X_train_pad, y_train_encoded, epochs=10, validation_data=(X_test_pad, y_test_encoded))

import matplotlib.pyplot as plt

plt.plot(verim.history['accuracy'])
plt.plot(verim.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(verim.history['loss'])
plt.plot(verim.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

hbr  = pd.read_csv('scraped_data.csv')

hbr = hbr.dropna()
hbr

sonhaber = []
H = hbr["Title"].values
for i in range(len(H)):
    H_ = harfdegistir(H[i])
    sonhaber.append(H_)

hbr['Title'] = sonhaber

hbr

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
sample_seq = tokenizer.texts_to_sequences(hbr['Title'])
sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post')

from sklearn.preprocessing import LabelEncoder
predictions = model.predict(sample_pad)
predicted_classes = predictions.argmax(axis=-1)
predicted_categories = le.inverse_transform(predicted_classes)
# Tahminleri DataFrame'e ekleyerek kategorize edilmiş veriyi oluşturma
result_df = pd.DataFrame({'İçerik': hbr['Title'], 'Tahmin': predicted_categories})
result_df.to_csv('haber_tahminler.csv', index=False)
# Elde edilen sonuçları görüntüleme
print(result_df)