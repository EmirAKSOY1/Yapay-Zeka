# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cetXkrWkTc6L0x4X7JvKZJzo27MwJi0I
"""

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
nltk.download('stopwords')
nltk.download('punkt')
import re
def harfdegistir(cumle):
    listcumle0 = list(cumle)
    for i in range(0,len(listcumle0)):
        if listcumle0[i] == "ü":
            listcumle0[i] = "u"
        elif listcumle0[i] == "Ü":
            listcumle0[i] = "U"
        elif listcumle0[i] == "ö":
            listcumle0[i] = "o"
        elif listcumle0[i] == "Ö":
            listcumle0[i] = "O"
        elif listcumle0[i] == "İ":
            listcumle0[i] = "I"
        elif listcumle0[i] == "ç":
            listcumle0[i] = "c"
        elif listcumle0[i] == "Ç":
            listcumle0[i] = "C"
        elif listcumle0[i] == "ğ":
            listcumle0[i] = "g"
        elif listcumle0[i] == "Ğ":
            listcumle0[i] = "G"
        elif listcumle0[i] == "ş":
            listcumle0[i] = "s"
        elif listcumle0[i] == "Ş":
            listcumle0[i] = "S"
        elif listcumle0[i] == "ı":
            listcumle0[i] = "i"

    cumle0 = ''.join(listcumle0)

    cumle1 = re.sub("[^a-zA-Z]", " ", cumle0)
    cumle2 = cumle1.lower()

    cumle2 = nltk.word_tokenize(cumle2)
    cumle2 = [word for word in cumle2 if not word in set(stopwords.words("turkish"))]

    cumle3 = " ".join(cumle2)

    return cumle3
df = pd.read_csv('yorumlar.csv',encoding="utf-16")
df = df.rename({'Görüş': 'Gorus'}, axis=1)

df= df.dropna()
SonGorus = []
X = df["Gorus"].values
for i in range(len(X)):
    X_ = harfdegistir(X[i])
    SonGorus.append(X_)

df['Gorus'] = SonGorus

df

X_train, X_test, y_train, y_test = train_test_split(df['Gorus'], df['Durum'], test_size=0.2, random_state=42)

le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

max_words = 1000
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train)

X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

max_len = 100  # Cümlenin maksimum uzunluğu
X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')

from tensorflow.keras.layers import Bidirectional, Dropout

# Modeli oluştur
model = Sequential()
model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))
model.add(Bidirectional(LSTM(128, return_sequences=True)))
model.add(Dropout(0.2))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.2))
model.add(Dense(3, activation='softmax'))
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train_pad, y_train_encoded, epochs=10, validation_data=(X_test_pad, y_test_encoded))

hbr = pd.read_csv('cekilen_yorum.csv', encoding='utf-8')
hbr.head()



test_loss, test_acc = model.evaluate(X_test_pad)

print('Test Loss:', test_loss)
print('Test Accuracy:', test_acc)

SonYorum = []
A = hbr["comment"].values
for i in range(len(A)):
    A_ = harfdegistir(A[i])
    SonYorum.append(A_)

hbr['comment'] = SonYorum

hbr

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
sample_seq = tokenizer.texts_to_sequences(hbr['comment'])
sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post')

from sklearn.preprocessing import LabelEncoder
predictions = model.predict(sample_pad)
predicted_classes = predictions.argmax(axis=-1)
predicted_categories = le.inverse_transform(predicted_classes)
# Tahminleri DataFrame'e ekleyerek kategorize edilmiş veriyi oluşturma
result_df = pd.DataFrame({'İçerik': hbr['comment'], 'Tahmin': predicted_categories})
result_df.to_csv('yorum_tahminler.csv', index=False)
# Elde edilen sonuçları görüntüleme
print(result_df)